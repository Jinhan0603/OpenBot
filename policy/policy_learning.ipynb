{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jinhan0603/OpenBot/blob/master/policy/policy_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 셀 A 최초 1회\n",
        "**목적** Opnebot과 Colab 환경 맞추기\n",
        "> Colab(Py3.12)과 맞는 TF/Numpy 조합 설치\n",
        "\n"
      ],
      "metadata": {
        "id": "eg3g1QX3ZU8u"
      },
      "id": "eg3g1QX3ZU8u"
    },
    {
      "cell_type": "code",
      "source": [
        "# [한글] Colab(Py3.12)과 호환되는 기본 스택 설치\n",
        "# - TF 2.20.0 + NumPy 2.0.x 조합\n",
        "# - ml-dtypes는 TF가 자동으로(>=0.5.1) 설치하므로 지정하지 않습니다.\n",
        "\n",
        "!pip uninstall -y jax jaxlib chex optax flax \\\n",
        "  tensorflow-text tensorflow-decision-forests tf-keras tensorstore \\\n",
        "  orbax-checkpoint tensorflow-hub dopamine-rl albumentations albucore \\\n",
        "  pymc pytensor bigframes ydf -qq\n",
        "\n",
        "!pip install -q --upgrade --force-reinstall tensorflow==2.20.0 numpy==2.0.2\n",
        "\n",
        "# (선택) 경고 줄이기: protobuf/pillow/requests/jedi 버전 맞춤\n",
        "!pip install -q \"protobuf<6,>=5.28.0\" \"pillow<12.0\" \"requests==2.32.4\" \"jedi>=0.16\"\n",
        "\n",
        "# 설치 확인(ml_dtypes는 0.5.1+면 정상)\n",
        "!pip show ml-dtypes | sed -n '1,5p'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9og2P6fZTGL",
        "outputId": "96818dbd-2f69-4419-94a3-ea85a5bfe1b8"
      },
      "id": "T9og2P6fZTGL",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.7/620.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m106.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m129.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.2/323.2 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m143.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.4/121.4 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.3/163.3 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.5/153.5 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.8/408.8 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m131.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.3/87.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "keras-hub 0.21.1 requires tensorflow-text; platform_system != \"Windows\", which is not installed.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.0 which is incompatible.\n",
            "gradio 5.49.1 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.33.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.8/64.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m112.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hName: ml_dtypes\n",
            "Version: 0.5.3\n",
            "Summary: ml_dtypes is a stand-alone implementation of several NumPy dtype extensions used in machine learning.\n",
            "Home-page: https://github.com/jax-ml/ml_dtypes\n",
            "Author: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**실행 후**\n",
        "> 세션 다시 시작(런타임 → 세션 다시 시작)"
      ],
      "metadata": {
        "id": "WEdoTyi0aDrB"
      },
      "id": "WEdoTyi0aDrB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 셀 B - 버전/GPU 확인\n",
        "목적 : 설치 검증"
      ],
      "metadata": {
        "id": "OWnjhur3Shfi"
      },
      "id": "OWnjhur3Shfi"
    },
    {
      "cell_type": "code",
      "source": [
        "# [한글] 설치된 버전 및 GPU 인식 확인\n",
        "import numpy as np, tensorflow as tf\n",
        "print(\"NumPy:\", np.__version__)       # 기대: 2.0.x\n",
        "print(\"TensorFlow:\", tf.__version__)  # 기대: 2.20.0\n",
        "print(\"GPU:\", tf.test.gpu_device_name() or \"CPU 사용\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QElAvvrNbBdA",
        "outputId": "7caec54b-3db2-484a-89cc-b18ebd53c499"
      },
      "id": "QElAvvrNbBdA",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy: 2.0.2\n",
            "TensorFlow: 2.20.0\n",
            "GPU: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 셀 C - 기본 임포트/로그 억제\n",
        "목적 : 불필요한 로그 줄이고 기본 도구 준비"
      ],
      "metadata": {
        "id": "Au0giog_bbox"
      },
      "id": "Au0giog_bbox"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "71fe81dc",
      "metadata": {
        "id": "71fe81dc"
      },
      "outputs": [],
      "source": [
        "# [한글] 학습에 자주 쓰는 라이브러리 임포트 + 로그 억제\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import IPython.display as display\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time, os\n",
        "import absl.logging\n",
        "\n",
        "absl.logging.set_verbosity(absl.logging.ERROR)\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"   # TF Info/Warning 숨김\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\"  # (Mac용 워크어라운드, 넣어도 무해)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 셀 D - Google Drive 마운트\n",
        "목적 : 드라이브 연결"
      ],
      "metadata": {
        "id": "mgzk5N8jKIc9"
      },
      "id": "mgzk5N8jKIc9"
    },
    {
      "cell_type": "code",
      "source": [
        "# [한글] Google Drive 마운트 (권한 승인 필요)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzLevczP9-Tw",
        "outputId": "9ad23ed9-55c8-4c9d-b448-108f51e8061a"
      },
      "id": "mzLevczP9-Tw",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**특이사항** : Opnebot에서 학습 시킨 데이터 ZIP 파일은\n",
        "마운트가 끝나면, Drive의 루트에 OpenBotData 같은 새 폴더를 만들고, PC에서 ZIP 두 개를 직접 Drive로 업로드! (드라이브 웹 UI나 Colab 파일창 상단 업로드 버튼 사용)"
      ],
      "metadata": {
        "id": "ILehyyCkcbAO"
      },
      "id": "ILehyyCkcbAO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 셀 E - ZIP 해제(충돌 방지 분리 폴더)\n",
        "목적 : ZIP을 /content/data/run1, run2에 해제"
      ],
      "metadata": {
        "id": "mmMsDz6TKNPn"
      },
      "id": "mmMsDz6TKNPn"
    },
    {
      "cell_type": "code",
      "source": [
        "# [한글] 같은 이름 파일 덮어쓰기 방지용으로 각각 폴더에 풀기\n",
        "!rm -rf /content/data && mkdir -p /content/data/run1 /content/data/run2\n",
        "!unzip -oq \"/content/drive/MyDrive/OpenBotData/20251031_145012.zip\" -d /content/data/run1\n",
        "!unzip -oq \"/content/drive/MyDrive/OpenBotData/20251031_145241.zip\" -d /content/data/run2\n",
        "!ls -al /content/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-V2B4Gc_aO-",
        "outputId": "8b5d57d9-13d8-4326-b3d9-353e6cefb2d5"
      },
      "id": "4-V2B4Gc_aO-",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 16\n",
            "drwxr-xr-x 4 root root 4096 Oct 31 08:46 .\n",
            "drwxr-xr-x 1 root root 4096 Oct 31 08:46 ..\n",
            "drwxr-xr-x 4 root root 4096 Oct 31 08:46 run1\n",
            "drwxr-xr-x 4 root root 4096 Oct 31 08:46 run2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 셀 F - 저장소 받기 + 파이썬 경로 추가\n",
        "목적 : OpenBot 코드를 가져오고, 파이썬이 찾을 수 있게 경로 추가"
      ],
      "metadata": {
        "id": "G8-6sQ38Ub_g"
      },
      "id": "G8-6sQ38Ub_g"
    },
    {
      "cell_type": "code",
      "source": [
        "# [한글] OpenBot 저장소가 없으면 clone, 있으면 최신으로 갱신\n",
        "import os, sys, importlib, subprocess, shlex\n",
        "\n",
        "if not os.path.isdir(\"/content/OpenBot/.git\"):\n",
        "    !git clone https://github.com/Jinhan0603/OpenBot.git /content/OpenBot\n",
        "else:\n",
        "    # (선택) 최신 갱신\n",
        "    !git -C /content/OpenBot pull --ff-only\n",
        "\n",
        "# 파이썬 모듈 경로 추가\n",
        "if \"/content/OpenBot/policy\" not in sys.path:\n",
        "    sys.path.insert(0, \"/content/OpenBot/policy\")\n",
        "importlib.invalidate_caches()\n",
        "\n",
        "# openbot 패키지 폴더 존재 확인\n",
        "assert os.path.isdir(\"/content/OpenBot/policy/openbot\"), \"openbot 패키지가 보이지 않습니다.\"\n",
        "print(\"openbot path OK\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f4KyzxvUUVl",
        "outputId": "ccb9a70a-b416-4dd2-b432-47368a1b6816"
      },
      "id": "8f4KyzxvUUVl",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/OpenBot'...\n",
            "remote: Enumerating objects: 15303, done.\u001b[K\n",
            "remote: Counting objects: 100% (555/555), done.\u001b[K\n",
            "remote: Compressing objects: 100% (362/362), done.\u001b[K\n",
            "remote: Total 15303 (delta 281), reused 193 (delta 193), pack-reused 14748 (from 3)\u001b[K\n",
            "Receiving objects: 100% (15303/15303), 235.27 MiB | 17.37 MiB/s, done.\n",
            "Resolving deltas: 100% (8448/8448), done.\n",
            "Updating files: 100% (2153/2153), done.\n",
            "openbot path OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 셀 G - OpenBot 임포트 확인\n",
        "목적 : 실제로 import가 되는지 확인"
      ],
      "metadata": {
        "id": "dUKbWJyJKQmw"
      },
      "id": "dUKbWJyJKQmw"
    },
    {
      "cell_type": "code",
      "source": [
        "# [한글] OpenBot 모듈 임포트 테스트\n",
        "from openbot import dataloader, data_augmentation, utils, train\n",
        "print(\"openbot import OK\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTYStm7sCosl",
        "outputId": "19db3b11-7270-4450-c630-b33dfb49b660"
      },
      "id": "fTYStm7sCosl",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default GPU Device:/device:GPU:0\n",
            "openbot import OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 셀 H - OpenBot이 기대하는 폴더 구조로 복사\n",
        "목적 : 노트북/코드가 찾는 표준 경로에 데이터 배치"
      ],
      "metadata": {
        "id": "1JjLouHDdCqj"
      },
      "id": "1JjLouHDdCqj"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2ac37fbe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ac37fbe",
        "outputId": "473a8375-1157-4531-86fb-098ce132dd89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/OpenBot/policy/dataset\n",
            "/content/OpenBot/policy/dataset/train_data\n",
            "/content/OpenBot/policy/dataset/train_data/my_dataset_1\n",
            "/content/OpenBot/policy/dataset/train_data/my_dataset_1/run1\n",
            "/content/OpenBot/policy/dataset/test_data\n",
            "/content/OpenBot/policy/dataset/test_data/my_dataset_2\n",
            "/content/OpenBot/policy/dataset/test_data/my_dataset_2/run2\n",
            "/content/OpenBot/policy/dataset/uploaded\n"
          ]
        }
      ],
      "source": [
        "# [한글] OpenBot 표준 데이터 경로에 복사\n",
        "!mkdir -p /content/OpenBot/policy/dataset/train_data/my_dataset_1\n",
        "!mkdir -p /content/OpenBot/policy/dataset/test_data/my_dataset_2\n",
        "!cp -r /content/data/run1 /content/OpenBot/policy/dataset/train_data/my_dataset_1/\n",
        "!cp -r /content/data/run2 /content/OpenBot/policy/dataset/test_data/my_dataset_2/\n",
        "\n",
        "# 확인\n",
        "!find /content/OpenBot/policy/dataset -maxdepth 3 -type d -print\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc941e8e",
      "metadata": {
        "id": "bc941e8e"
      },
      "source": [
        "# 셀 I - 데이터 경로 지정\n",
        "> 노트북 기본 예시는 dataset_dir = \"dataset\"(상대경로)인데, Colab의 작업 디렉터리에 따라 빗나갈 수 있어요. openbot이 가지고 있는 절대경로를 쓰면 이후 단계와 정확히 일치합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "823ef8f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "823ef8f3",
        "outputId": "81a0732a-36ab-475a-e8c6-18b3e4a07f23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset_dir   : /content/OpenBot/policy/dataset\n",
            "train_data_dir: /content/OpenBot/policy/dataset/train_data\n",
            "test_data_dir : /content/OpenBot/policy/dataset/test_data\n"
          ]
        }
      ],
      "source": [
        "# [한글] 학습에 사용할 데이터셋 경로 지정\n",
        "# - openbot 패키지의 기본 경로를 그대로 사용하면 이후 단계와 경로가 일치합니다.\n",
        "import os\n",
        "import openbot as ob\n",
        "\n",
        "dataset_dir = ob.dataset_dir                     # /content/OpenBot/policy/dataset\n",
        "dataset_name = \"openbot\"                         # 표기용 이름\n",
        "train_data_dir = os.path.join(dataset_dir, \"train_data\")\n",
        "test_data_dir  = os.path.join(dataset_dir, \"test_data\")\n",
        "\n",
        "print(\"dataset_dir   :\", dataset_dir)\n",
        "print(\"train_data_dir:\", train_data_dir)\n",
        "print(\"test_data_dir :\", test_data_dir)\n",
        "assert os.path.isdir(train_data_dir), \"train_data_dir 폴더가 없습니다.\"\n",
        "assert os.path.isdir(test_data_dir),  \"test_data_dir 폴더가 없습니다.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 셀 J - 폴더 구조 점검 및 자동 정리(필요 시)\n",
        "\n",
        "\n",
        "> ZIP을 run1, run2 같은 중간 폴더에 풀면 세션 폴더가 한 단계 더 깊어질 수 있어요. 이 셀은 그런 경우를 자동으로 올바른 깊이로 이동시켜 줍니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "xZLwEunKfu5J"
      },
      "id": "xZLwEunKfu5J"
    },
    {
      "cell_type": "code",
      "source": [
        "# [한글] 데이터 구조가 올바른지 검사하고, 한 단계 더 깊게 들어간 경우 자동으로 평탄화합니다.\n",
        "# 기대 구조:\n",
        "#  train_data/\n",
        "#    └─ my_dataset_1/\n",
        "#         └─ <각 세션>/ (images/, sensor_data/)\n",
        "#  test_data/\n",
        "#    └─ my_dataset_2/\n",
        "#         └─ <각 세션>/ (images/, sensor_data/)\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "def ensure_flat(ds_root: Path):\n",
        "  for ds in ds_root.iterdir():\n",
        "    if not ds.is_dir():\n",
        "      continue\n",
        "    # 올바른 경우: ds/<session>/sensor_data 존재\n",
        "    ok = list(ds.glob(\"*/sensor_data\"))\n",
        "    if ok:\n",
        "      continue\n",
        "    # 잘못된 경우(한 단계 더 깊음): ds/*/*/sensor_data -> 세션 폴더를 한 단계 위로 이동\n",
        "    deep = list(ds.glob(\"*/*/sensor_data\"))\n",
        "    for sd in deep:\n",
        "      session = sd.parent\n",
        "      target_parent = ds\n",
        "      target = target_parent / session.name\n",
        "      if target.exists():\n",
        "        i = 1\n",
        "        while (target_parent / f\"{session.name}_{i}\").exists():\n",
        "          i += 1\n",
        "        target = target_parent / f\"{session.name}_{i}\"\n",
        "      print(f\"[move] {session} -> {target_parent}\")\n",
        "      shutil.move(str(session), str(target))\n",
        "\n",
        "ensure_flat(Path(train_data_dir))\n",
        "ensure_flat(Path(test_data_dir))\n",
        "\n",
        "# 요약: 세션/이미지 개수\n",
        "def count_sessions(root: str) -> int:\n",
        "  return sum(1 for p in Path(root).glob(\"*/\") if p.is_dir())\n",
        "def count_imgs(root: str) -> int:\n",
        "  return len(list(Path(root).glob(\"*/*/images/*\")))\n",
        "\n",
        "print(\"train sessions:\", count_sessions(train_data_dir), \"images:\", count_imgs(train_data_dir))\n",
        "print(\"test  sessions:\", count_sessions(test_data_dir),  \"images:\", count_imgs(test_data_dir))\n"
      ],
      "metadata": {
        "id": "8RGXj89Yf4Ff",
        "outputId": "f303ef2a-c14f-4d4c-e4a0-4dc5283ca219",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8RGXj89Yf4Ff",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train sessions: 1 images: 1897\n",
            "test  sessions: 1 images: 2003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 셀 K - 샘플 경로 빠른 확인\n",
        "> 세션/이미지 경로가 기대대로 보이면 다음 섹션(‘Hyperparameters’)로 넘어가면 됩니다."
      ],
      "metadata": {
        "id": "YIOHuj5af_ZL"
      },
      "id": "YIOHuj5af_ZL"
    },
    {
      "cell_type": "code",
      "source": [
        "# [한글] 샘플 이미지 경로를 몇 개 출력해 구조가 맞는지 빠르게 확인합니다.\n",
        "from pathlib import Path\n",
        "\n",
        "sample_train = list(Path(train_data_dir).glob(\"*/*/images/*\"))[:3]\n",
        "sample_test  = list(Path(test_data_dir).glob(\"*/*/images/*\"))[:3]\n",
        "\n",
        "print(\"sample train:\", [str(p) for p in sample_train] or \"없음\")\n",
        "print(\"sample test :\", [str(p) for p in sample_test]  or \"없음\")\n"
      ],
      "metadata": {
        "id": "nrQVr2D6gGlp",
        "outputId": "60426e55-c36e-450b-e7b7-ec07195275b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "nrQVr2D6gGlp",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample train: ['/content/OpenBot/policy/dataset/train_data/my_dataset_1/run1/images/7851_crop.jpeg', '/content/OpenBot/policy/dataset/train_data/my_dataset_1/run1/images/7840_crop.jpeg', '/content/OpenBot/policy/dataset/train_data/my_dataset_1/run1/images/8209_crop.jpeg']\n",
            "sample test : ['/content/OpenBot/policy/dataset/test_data/my_dataset_2/run2/images/1799_crop.jpeg', '/content/OpenBot/policy/dataset/test_data/my_dataset_2/run2/images/506_crop.jpeg', '/content/OpenBot/policy/dataset/test_data/my_dataset_2/run2/images/2346_crop.jpeg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4388bbaa",
      "metadata": {
        "id": "4388bbaa"
      },
      "source": [
        "# Hyperparameters\n",
        "<a id='hyperparameters'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "625eb2bd",
      "metadata": {
        "id": "625eb2bd"
      },
      "source": [
        "You may have to tune the learning rate and batch size depending on your available compute resources and dataset. As a general rule of thumb, if you increase the batch size by a factor of n, you can increase the learning rate by a factor of sqrt(n). In order to accelerate training and make it more smooth, you should increase the batch size as much as possible. In our paper we used a batch size of 128. For debugging and hyperparamter tuning, you can set the number of epochs to a small value like 10. If you want to train a model which will achieve good performance, you should set it to 50 or more. In our paper we used 100."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a14c7cac",
      "metadata": {
        "id": "a14c7cac"
      },
      "outputs": [],
      "source": [
        "params = train.Hyperparameters()\n",
        "\n",
        "params.MODEL = \"pilot_net\"  # choices: \"pilot_net\",\"cil_mobile\",\"cil_mobile_fast\",\"cil\"\n",
        "params.POLICY = \"autopilot\"  # choices: \"autopilot\",\"point_goal_nav\"\n",
        "params.TRAIN_BATCH_SIZE = 128\n",
        "params.TEST_BATCH_SIZE = 16\n",
        "params.LEARNING_RATE = 0.0003\n",
        "params.NUM_EPOCHS = 100\n",
        "params.BATCH_NORM = True  # use batch norm (recommended)\n",
        "params.FLIP_AUG = False  # flip image and controls as augmentation (only autopilot)\n",
        "params.CMD_AUG = False  # randomize high-level command as augmentation (only autopilot)\n",
        "params.USE_LAST = False  # resume training from last checkpoint\n",
        "params.WANDB = False\n",
        "# policy = \"autopilot\": images are expected to be 256x96 - no cropping required\n",
        "# policy = \"point_goal_nav\": images are expected to be 160x120 - cropping to 160x90\n",
        "params.IS_CROP = params.POLICY == \"point_goal_nav\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82ac0929",
      "metadata": {
        "id": "82ac0929"
      },
      "source": [
        "# Pre-process the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b4494b4",
      "metadata": {
        "id": "4b4494b4"
      },
      "outputs": [],
      "source": [
        "tr = train.Training(params)\n",
        "tr.dataset_name = dataset_name\n",
        "tr.train_data_dir = train_data_dir\n",
        "tr.test_data_dir = test_data_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abfc9b9b",
      "metadata": {
        "id": "abfc9b9b"
      },
      "source": [
        "Running this for the first time will take some time. This code will match image frames to the controls (labels) and indicator signals (commands).  By default, data samples where the vehicle was stationary will be removed. If this is not desired, you need to set `tr.remove_zeros = False`. If you have made any changes to the sensor files, changed `remove_zeros` or moved your dataset to a new directory, you need to set `tr.redo_matching = True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9d78141",
      "metadata": {
        "id": "e9d78141"
      },
      "outputs": [],
      "source": [
        "tr.redo_matching = False\n",
        "tr.remove_zeros = True\n",
        "train.process_data(tr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c531aecf",
      "metadata": {
        "id": "c531aecf"
      },
      "outputs": [],
      "source": [
        "import threading\n",
        "\n",
        "\n",
        "def broadcast(event, payload=None):\n",
        "    print(event, payload)\n",
        "\n",
        "\n",
        "event = threading.Event()\n",
        "my_callback = train.MyCallback(broadcast, event)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fc670c9",
      "metadata": {
        "id": "2fc670c9"
      },
      "source": [
        "In the next step, you can convert your dataset to a tfrecord, a data format optimized for training. You can skip this step if you already created a tfrecord before or if you want to train using the files directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59336936",
      "metadata": {
        "id": "59336936"
      },
      "outputs": [],
      "source": [
        "train.create_tfrecord(my_callback, policy=tr.hyperparameters.POLICY)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0a4a1cf",
      "metadata": {
        "id": "b0a4a1cf"
      },
      "source": [
        "# Load the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a51ee383",
      "metadata": {
        "id": "a51ee383"
      },
      "source": [
        "If you did not create a tfrecord and want to load and buffer files from disk directly, set `no_tf_record = True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc2d2068",
      "metadata": {
        "id": "bc2d2068"
      },
      "outputs": [],
      "source": [
        "no_tf_record = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "082c90bf",
      "metadata": {
        "id": "082c90bf"
      },
      "outputs": [],
      "source": [
        "if no_tf_record:\n",
        "    tr.train_data_dir = train_data_dir\n",
        "    tr.test_data_dir = test_data_dir\n",
        "    train.load_data(tr, verbose=0)\n",
        "else:\n",
        "    tr.train_data_dir = os.path.join(dataset_dir, \"tfrecords/train.tfrec\")\n",
        "    tr.test_data_dir = os.path.join(dataset_dir, \"tfrecords/test.tfrec\")\n",
        "    train.load_tfrecord(tr, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edf34f3f",
      "metadata": {
        "id": "edf34f3f"
      },
      "outputs": [],
      "source": [
        "# Select interactive backend to show inline\n",
        "%matplotlib inline\n",
        "utils.show_batch(dataset=tr.train_ds, policy=tr.hyperparameters.POLICY, model=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a5d0f77",
      "metadata": {
        "id": "0a5d0f77"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71034420",
      "metadata": {
        "id": "71034420"
      },
      "source": [
        "The number of epochs is proportional to the training time. One epoch means going through the complete dataset once. Increasing `NUM_EPOCHS` will mean longer training time, but generally leads to better performance. To get familiar with the code it can be set to small values like `5` or `10`. To train a model that performs well, it should be set to values between `50` and `200`. Setting `USE_LAST` to `true` will resume the training from the last checkpoint. The default values are `NUM_EPOCHS = 100` and `USE_LAST = False`. They are set in [Hyperparameters](#hyperparameters)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "894cd54f",
      "metadata": {
        "id": "894cd54f"
      },
      "outputs": [],
      "source": [
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(os.path.join(os.getcwd(), \"models\", tr.model_name), exist_ok=True)\n",
        "\n",
        "# params.NUM_EPOCHS = 200\n",
        "# params.USE_LAST = True\n",
        "train.do_training(tr, my_callback, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cfd4aac",
      "metadata": {
        "id": "0cfd4aac"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f623b65f",
      "metadata": {
        "id": "f623b65f"
      },
      "source": [
        "The loss and mean absolute error should decrease. This indicates that the model is fitting the data well. The custom metrics (direction and angle) should go towards 1. These provide some additional insight to the training progress. The direction metric measures weather or not predictions are in the same direction as the labels. Similarly the angle metric measures if the prediction is within a small angle of the labels. The intuition is that driving in the right direction with the correct steering angle is most critical part for good final performance."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4867aaa7",
      "metadata": {
        "id": "4867aaa7"
      },
      "source": [
        "### Plot metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ca0b291",
      "metadata": {
        "id": "8ca0b291"
      },
      "outputs": [],
      "source": [
        "x = np.arange(tr.INITIAL_EPOCH + 1, tr.history.params[\"epochs\"] + 1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efd65e1a",
      "metadata": {
        "id": "efd65e1a"
      },
      "outputs": [],
      "source": [
        "plt.figure().gca().xaxis.get_major_locator().set_params(integer=True)\n",
        "plt.plot(x, tr.history.history[\"loss\"], label=\"loss\")\n",
        "plt.plot(x, tr.history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.savefig(os.path.join(tr.log_path, \"loss.png\"), bbox_inches=\"tight\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97e98f63",
      "metadata": {
        "id": "97e98f63"
      },
      "outputs": [],
      "source": [
        "plt.figure().gca().xaxis.get_major_locator().set_params(integer=True)\n",
        "plt.plot(x, tr.history.history[\"mean_absolute_error\"], label=\"mean_absolute_error\")\n",
        "plt.plot(\n",
        "    x, tr.history.history[\"val_mean_absolute_error\"], label=\"val_mean_absolute_error\"\n",
        ")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Mean Absolute Error\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.savefig(os.path.join(tr.log_path, \"error.png\"), bbox_inches=\"tight\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa1752d7",
      "metadata": {
        "id": "aa1752d7"
      },
      "outputs": [],
      "source": [
        "plt.figure().gca().xaxis.get_major_locator().set_params(integer=True)\n",
        "plt.plot(x, tr.history.history[\"direction_metric\"], label=\"direction_metric\")\n",
        "plt.plot(x, tr.history.history[\"val_direction_metric\"], label=\"val_direction_metric\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Direction Metric\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig(os.path.join(tr.log_path, \"direction.png\"), bbox_inches=\"tight\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9de04eec",
      "metadata": {
        "id": "9de04eec"
      },
      "outputs": [],
      "source": [
        "plt.figure().gca().xaxis.get_major_locator().set_params(integer=True)\n",
        "plt.plot(x, tr.history.history[\"angle_metric\"], label=\"angle_metric\")\n",
        "plt.plot(x, tr.history.history[\"val_angle_metric\"], label=\"val_angle_metric\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Angle Metric\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig(os.path.join(tr.log_path, \"angle.png\"), bbox_inches=\"tight\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e72c1de3",
      "metadata": {
        "id": "e72c1de3"
      },
      "source": [
        "### Save tf lite models for best train, best val and last checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92a1ef62",
      "metadata": {
        "id": "92a1ef62"
      },
      "outputs": [],
      "source": [
        "best_train_checkpoint = \"cp-best-train.ckpt\"\n",
        "best_train_tflite = utils.generate_tflite(tr.checkpoint_path, best_train_checkpoint)\n",
        "utils.save_tflite(best_train_tflite, tr.checkpoint_path, \"best-train\")\n",
        "best_train_index = np.argmin(np.array(tr.history.history[\"loss\"]))\n",
        "print(\n",
        "    \"Best Train Checkpoint (epoch %s) - angle: %.4f, val_angle: %.4f, direction: %.4f, val_direction: %.4f\"\n",
        "    % (\n",
        "        best_train_index,\n",
        "        tr.history.history[\"angle_metric\"][best_train_index],\n",
        "        tr.history.history[\"val_angle_metric\"][best_train_index],\n",
        "        tr.history.history[\"direction_metric\"][best_train_index],\n",
        "        tr.history.history[\"val_direction_metric\"][best_train_index],\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb605b90",
      "metadata": {
        "id": "bb605b90"
      },
      "outputs": [],
      "source": [
        "best_val_checkpoint = \"cp-best-val.ckpt\"\n",
        "best_val_tflite = utils.generate_tflite(tr.checkpoint_path, best_val_checkpoint)\n",
        "utils.save_tflite(best_val_tflite, tr.checkpoint_path, \"best\")\n",
        "utils.save_tflite(best_val_tflite, tr.checkpoint_path, \"best-val\")\n",
        "best_val_index = np.argmin(np.array(tr.history.history[\"val_loss\"]))\n",
        "print(\n",
        "    \"Best Val Checkpoint (epoch %s) - angle: %.4f, val_angle: %.4f, direction: %.4f, val_direction: %.4f\"\n",
        "    % (\n",
        "        best_val_index,\n",
        "        tr.history.history[\"angle_metric\"][best_val_index],\n",
        "        tr.history.history[\"val_angle_metric\"][best_val_index],\n",
        "        tr.history.history[\"direction_metric\"][best_val_index],\n",
        "        tr.history.history[\"val_direction_metric\"][best_val_index],\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e2b1644",
      "metadata": {
        "id": "0e2b1644"
      },
      "outputs": [],
      "source": [
        "last_checkpoint = \"cp-last.ckpt\"\n",
        "last_tflite = utils.generate_tflite(tr.checkpoint_path, last_checkpoint)\n",
        "utils.save_tflite(last_tflite, tr.checkpoint_path, \"last\")\n",
        "print(\n",
        "    \"Last Checkpoint - angle: %.4f, val_angle: %.4f, direction: %.4f, val_direction: %.4f\"\n",
        "    % (\n",
        "        tr.history.history[\"angle_metric\"][-1],\n",
        "        tr.history.history[\"val_angle_metric\"][-1],\n",
        "        tr.history.history[\"direction_metric\"][-1],\n",
        "        tr.history.history[\"val_direction_metric\"][-1],\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0c57018",
      "metadata": {
        "id": "d0c57018"
      },
      "source": [
        "### Evaluate the best model (train loss) on the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04a03c6d",
      "metadata": {
        "id": "04a03c6d"
      },
      "outputs": [],
      "source": [
        "best_train_model = utils.load_model(\n",
        "    os.path.join(tr.checkpoint_path, best_train_checkpoint),\n",
        "    tr.loss_fn,\n",
        "    tr.metric_list,\n",
        "    tr.custom_objects,\n",
        ")\n",
        "loss, mae, direction, angle = best_train_model.evaluate(\n",
        "    tr.train_ds,\n",
        "    steps=tr.image_count_train / tr.hyperparameters.TRAIN_BATCH_SIZE,\n",
        "    verbose=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92462709",
      "metadata": {
        "id": "92462709"
      },
      "outputs": [],
      "source": [
        "utils.show_batch(\n",
        "    dataset=tr.train_ds, policy=tr.hyperparameters.POLICY, model=best_train_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10a078b1",
      "metadata": {
        "id": "10a078b1"
      },
      "outputs": [],
      "source": [
        "utils.compare_tf_tflite(best_train_model, best_train_tflite)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2ad2605",
      "metadata": {
        "id": "b2ad2605"
      },
      "source": [
        "### Evaluate the best model (val loss) on the validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2ac5b20",
      "metadata": {
        "id": "e2ac5b20"
      },
      "outputs": [],
      "source": [
        "best_val_model = utils.load_model(\n",
        "    os.path.join(tr.checkpoint_path, best_val_checkpoint),\n",
        "    tr.loss_fn,\n",
        "    tr.metric_list,\n",
        "    tr.custom_objects,\n",
        ")\n",
        "loss, mae, direction, angle = best_val_model.evaluate(\n",
        "    tr.test_ds,\n",
        "    steps=tr.image_count_test / tr.hyperparameters.TEST_BATCH_SIZE,\n",
        "    verbose=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8e01e77",
      "metadata": {
        "id": "d8e01e77"
      },
      "outputs": [],
      "source": [
        "utils.show_batch(\n",
        "    dataset=tr.test_ds, policy=tr.hyperparameters.POLICY, model=best_val_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daf9dbac",
      "metadata": {
        "id": "daf9dbac"
      },
      "outputs": [],
      "source": [
        "utils.compare_tf_tflite(best_val_model, best_val_tflite)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29c9d606",
      "metadata": {
        "id": "29c9d606"
      },
      "source": [
        "# Save the notebook as HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c47915f",
      "metadata": {
        "id": "3c47915f"
      },
      "outputs": [],
      "source": [
        "utils.save_notebook()\n",
        "current_file = \"policy_learning.ipynb\"\n",
        "output_file = os.path.join(tr.log_path, \"notebook.html\")\n",
        "utils.output_HTML(current_file, output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa902ebd",
      "metadata": {
        "id": "fa902ebd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}