{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Opnebot 예제과 Colab 충돌 패키지 제거"
      ],
      "metadata": {
        "id": "zXD7SY-6Ti-e"
      },
      "id": "zXD7SY-6Ti-e"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y jax jaxlib chex optax flax \\\n",
        "  tensorflow-text tensorflow-decision-forests tf-keras tensorstore \\\n",
        "  orbax-checkpoint tensorflow-hub dopamine-rl albumentations albucore \\\n",
        "  pymc pytensor bigframes ydf"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrPKOkiyOIzh",
        "outputId": "82e29269-2445-4d84-af33-412ab34da120"
      },
      "id": "yrPKOkiyOIzh",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: jax 0.7.2\n",
            "Uninstalling jax-0.7.2:\n",
            "  Successfully uninstalled jax-0.7.2\n",
            "Found existing installation: jaxlib 0.7.2\n",
            "Uninstalling jaxlib-0.7.2:\n",
            "  Successfully uninstalled jaxlib-0.7.2\n",
            "Found existing installation: chex 0.1.90\n",
            "Uninstalling chex-0.1.90:\n",
            "  Successfully uninstalled chex-0.1.90\n",
            "Found existing installation: optax 0.2.6\n",
            "Uninstalling optax-0.2.6:\n",
            "  Successfully uninstalled optax-0.2.6\n",
            "Found existing installation: flax 0.10.7\n",
            "Uninstalling flax-0.10.7:\n",
            "  Successfully uninstalled flax-0.10.7\n",
            "Found existing installation: tensorflow-text 2.19.0\n",
            "Uninstalling tensorflow-text-2.19.0:\n",
            "  Successfully uninstalled tensorflow-text-2.19.0\n",
            "Found existing installation: tensorflow_decision_forests 1.12.0\n",
            "Uninstalling tensorflow_decision_forests-1.12.0:\n",
            "  Successfully uninstalled tensorflow_decision_forests-1.12.0\n",
            "Found existing installation: tf_keras 2.19.0\n",
            "Uninstalling tf_keras-2.19.0:\n",
            "  Successfully uninstalled tf_keras-2.19.0\n",
            "Found existing installation: tensorstore 0.1.78\n",
            "Uninstalling tensorstore-0.1.78:\n",
            "  Successfully uninstalled tensorstore-0.1.78\n",
            "Found existing installation: orbax-checkpoint 0.11.26\n",
            "Uninstalling orbax-checkpoint-0.11.26:\n",
            "  Successfully uninstalled orbax-checkpoint-0.11.26\n",
            "Found existing installation: tensorflow-hub 0.16.1\n",
            "Uninstalling tensorflow-hub-0.16.1:\n",
            "  Successfully uninstalled tensorflow-hub-0.16.1\n",
            "Found existing installation: dopamine_rl 4.1.2\n",
            "Uninstalling dopamine_rl-4.1.2:\n",
            "  Successfully uninstalled dopamine_rl-4.1.2\n",
            "Found existing installation: albumentations 2.0.8\n",
            "Uninstalling albumentations-2.0.8:\n",
            "  Successfully uninstalled albumentations-2.0.8\n",
            "Found existing installation: albucore 0.0.24\n",
            "Uninstalling albucore-0.0.24:\n",
            "  Successfully uninstalled albucore-0.0.24\n",
            "Found existing installation: pymc 5.26.1\n",
            "Uninstalling pymc-5.26.1:\n",
            "  Successfully uninstalled pymc-5.26.1\n",
            "Found existing installation: pytensor 2.35.1\n",
            "Uninstalling pytensor-2.35.1:\n",
            "  Successfully uninstalled pytensor-2.35.1\n",
            "Found existing installation: bigframes 2.27.0\n",
            "Uninstalling bigframes-2.27.0:\n",
            "  Successfully uninstalled bigframes-2.27.0\n",
            "Found existing installation: ydf 0.13.0\n",
            "Uninstalling ydf-0.13.0:\n",
            "  Successfully uninstalled ydf-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Colab 환경에 맞춰 다시 학습 패키지 설치"
      ],
      "metadata": {
        "id": "9N6aeeKfTvND"
      },
      "id": "9N6aeeKfTvND"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade --force-reinstall tensorflow==2.20.0 numpy==2.0.2\n",
        "!pip install -q \"protobuf<6,>=5.28.0\" \"pillow<12.0\" \"requests==2.32.4\" jedi>=0.16\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2m8gETHOQea",
        "outputId": "0a3c863e-4a40-48fd-e144-59b03cd2216e"
      },
      "id": "w2m8gETHOQea",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.7/620.7 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m111.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.2/323.2 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.4/121.4 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.3/163.3 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.5/153.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m138.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.8/408.8 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m136.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.3/87.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "keras-hub 0.21.1 requires tensorflow-text; platform_system != \"Windows\", which is not installed.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.0 which is incompatible.\n",
            "gradio 5.49.1 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.33.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show ml-dtypes | sed -n '1,5p'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ry0AwlrESQza",
        "outputId": "8fb813b8-9154-46df-8612-7cc63e2f0bd3"
      },
      "id": "Ry0AwlrESQza",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: ml_dtypes\n",
            "Version: 0.5.3\n",
            "Summary: ml_dtypes is a stand-alone implementation of several NumPy dtype extensions used in machine learning.\n",
            "Home-page: https://github.com/jax-ml/ml_dtypes\n",
            "Author: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "텐서플로우 설치 확인"
      ],
      "metadata": {
        "id": "OWnjhur3Shfi"
      },
      "id": "OWnjhur3Shfi"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, tensorflow as tf\n",
        "print(\"NumPy:\", np.__version__)       # 기대: 2.0.x\n",
        "print(\"TensorFlow:\", tf.__version__)  # 기대: 2.20.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZpKMRlYSjQj",
        "outputId": "b2cbcc2a-6848-4ad9-eab8-fbf3009a1895"
      },
      "id": "1ZpKMRlYSjQj",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy: 2.0.2\n",
            "TensorFlow: 2.20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if tf.test.gpu_device_name():\n",
        "    print(\"GPU:\", tf.test.gpu_device_name())\n",
        "else:\n",
        "    print(\"GPU not found; running on CPU.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7dzsn-wSoyq",
        "outputId": "73b38d38-9381-41f6-932d-f0d5c07f8bc8"
      },
      "id": "G7dzsn-wSoyq",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습 노트북을 시작할 때 필요한 도구 불러오기, 불필요한 메시지 줄여 깔끔하게 출력하는 준비단계"
      ],
      "metadata": {
        "id": "jcFaHmMyJ6mu"
      },
      "id": "jcFaHmMyJ6mu"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "71fe81dc",
      "metadata": {
        "id": "71fe81dc"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import IPython.display as display\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import absl.logging\n",
        "\n",
        "absl.logging.set_verbosity(absl.logging.ERROR)\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "# 0 = all messages are logged (default behavior)\n",
        "# 1 = INFO messages are not printed\n",
        "# 2 = INFO and WARNING messages are not printed\n",
        "# 3 = INFO, WARNING, and ERROR messages are not printed\n",
        "\n",
        "# On Mac you may encounter an error related to OMP, this is a workaround, but slows down the code\n",
        "# https://github.com/dmlc/xgboost/issues/1715\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 드라이브 마운트 :"
      ],
      "metadata": {
        "id": "mgzk5N8jKIc9"
      },
      "id": "mgzk5N8jKIc9"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzLevczP9-Tw",
        "outputId": "77e7b908-6cef-4830-e94c-b26c5596c1b4"
      },
      "id": "mzLevczP9-Tw",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. 데이터 압축 해제 :"
      ],
      "metadata": {
        "id": "mmMsDz6TKNPn"
      },
      "id": "mmMsDz6TKNPn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "2-1. 같은 이름 파일 덮어쓰기 방지용으로 각각 폴더에 풀기"
      ],
      "metadata": {
        "id": "KsybhIazUWgo"
      },
      "id": "KsybhIazUWgo"
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/data && mkdir -p /content/data/run1 /content/data/run2\n",
        "!unzip -oq \"/content/drive/MyDrive/OpenBotData/20251031_145012.zip\" -d /content/data/run1\n",
        "!unzip -oq \"/content/drive/MyDrive/OpenBotData/20251031_145241.zip\" -d /content/data/run2"
      ],
      "metadata": {
        "id": "4-V2B4Gc_aO-"
      },
      "id": "4-V2B4Gc_aO-",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2-2. OpenBot이 기대하는 폴더 구조로 복사"
      ],
      "metadata": {
        "id": "G8-6sQ38Ub_g"
      },
      "id": "G8-6sQ38Ub_g"
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/OpenBot/policy/dataset/train_data/my_dataset_1\n",
        "!mkdir -p /content/OpenBot/policy/dataset/test_data/my_dataset_2\n",
        "!cp -r /content/data/run1 /content/OpenBot/policy/dataset/train_data/my_dataset_1/\n",
        "!cp -r /content/data/run2 /content/OpenBot/policy/dataset/test_data/my_dataset_2/"
      ],
      "metadata": {
        "id": "8f4KyzxvUUVl"
      },
      "id": "8f4KyzxvUUVl",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. 저장소 받기 + 경로 추가 :"
      ],
      "metadata": {
        "id": "dUKbWJyJKQmw"
      },
      "id": "dUKbWJyJKQmw"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Jinhan0603/OpenBot.git\n",
        "import sys\n",
        "sys.path.append(\"/content/OpenBot/policy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTYStm7sCosl",
        "outputId": "b3cf490c-6480-46a9-d2f1-571d2427287c"
      },
      "id": "fTYStm7sCosl",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'OpenBot' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2ac37fbe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "2ac37fbe",
        "outputId": "aac7c269-fe59-4a8b-8fbf-cc9cd35f8008"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'openbot'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1719202228.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mopenbot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_augmentation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openbot'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from openbot import dataloader, data_augmentation, utils, train"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05c28641",
      "metadata": {
        "id": "05c28641"
      },
      "source": [
        "## Set train and test dirs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc941e8e",
      "metadata": {
        "id": "bc941e8e"
      },
      "source": [
        "Define the dataset directory and give it a name. Inside the dataset folder, there should be two folders, `train_data` and `test_data`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "823ef8f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "823ef8f3",
        "outputId": "05bc85fc-f111-4fa4-94cd-61d00a4cd586"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4000553971.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"dataset\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"openbot\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_data_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_data_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ],
      "source": [
        "dataset_dir = \"dataset\"\n",
        "dataset_name = \"openbot\"\n",
        "train_data_dir = os.path.join(dataset_dir, \"train_data\")\n",
        "test_data_dir = os.path.join(dataset_dir, \"test_data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4388bbaa",
      "metadata": {
        "id": "4388bbaa"
      },
      "source": [
        "## Hyperparameters\n",
        "<a id='hyperparameters'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "625eb2bd",
      "metadata": {
        "id": "625eb2bd"
      },
      "source": [
        "You may have to tune the learning rate and batch size depending on your available compute resources and dataset. As a general rule of thumb, if you increase the batch size by a factor of n, you can increase the learning rate by a factor of sqrt(n). In order to accelerate training and make it more smooth, you should increase the batch size as much as possible. In our paper we used a batch size of 128. For debugging and hyperparamter tuning, you can set the number of epochs to a small value like 10. If you want to train a model which will achieve good performance, you should set it to 50 or more. In our paper we used 100."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a14c7cac",
      "metadata": {
        "id": "a14c7cac"
      },
      "outputs": [],
      "source": [
        "params = train.Hyperparameters()\n",
        "\n",
        "params.MODEL = \"pilot_net\"  # choices: \"pilot_net\",\"cil_mobile\",\"cil_mobile_fast\",\"cil\"\n",
        "params.POLICY = \"autopilot\"  # choices: \"autopilot\",\"point_goal_nav\"\n",
        "params.TRAIN_BATCH_SIZE = 128\n",
        "params.TEST_BATCH_SIZE = 16\n",
        "params.LEARNING_RATE = 0.0003\n",
        "params.NUM_EPOCHS = 100\n",
        "params.BATCH_NORM = True  # use batch norm (recommended)\n",
        "params.FLIP_AUG = False  # flip image and controls as augmentation (only autopilot)\n",
        "params.CMD_AUG = False  # randomize high-level command as augmentation (only autopilot)\n",
        "params.USE_LAST = False  # resume training from last checkpoint\n",
        "params.WANDB = False\n",
        "# policy = \"autopilot\": images are expected to be 256x96 - no cropping required\n",
        "# policy = \"point_goal_nav\": images are expected to be 160x120 - cropping to 160x90\n",
        "params.IS_CROP = params.POLICY == \"point_goal_nav\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82ac0929",
      "metadata": {
        "id": "82ac0929"
      },
      "source": [
        "## Pre-process the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b4494b4",
      "metadata": {
        "id": "4b4494b4"
      },
      "outputs": [],
      "source": [
        "tr = train.Training(params)\n",
        "tr.dataset_name = dataset_name\n",
        "tr.train_data_dir = train_data_dir\n",
        "tr.test_data_dir = test_data_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abfc9b9b",
      "metadata": {
        "id": "abfc9b9b"
      },
      "source": [
        "Running this for the first time will take some time. This code will match image frames to the controls (labels) and indicator signals (commands).  By default, data samples where the vehicle was stationary will be removed. If this is not desired, you need to set `tr.remove_zeros = False`. If you have made any changes to the sensor files, changed `remove_zeros` or moved your dataset to a new directory, you need to set `tr.redo_matching = True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9d78141",
      "metadata": {
        "id": "e9d78141"
      },
      "outputs": [],
      "source": [
        "tr.redo_matching = False\n",
        "tr.remove_zeros = True\n",
        "train.process_data(tr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c531aecf",
      "metadata": {
        "id": "c531aecf"
      },
      "outputs": [],
      "source": [
        "import threading\n",
        "\n",
        "\n",
        "def broadcast(event, payload=None):\n",
        "    print(event, payload)\n",
        "\n",
        "\n",
        "event = threading.Event()\n",
        "my_callback = train.MyCallback(broadcast, event)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fc670c9",
      "metadata": {
        "id": "2fc670c9"
      },
      "source": [
        "In the next step, you can convert your dataset to a tfrecord, a data format optimized for training. You can skip this step if you already created a tfrecord before or if you want to train using the files directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59336936",
      "metadata": {
        "id": "59336936"
      },
      "outputs": [],
      "source": [
        "train.create_tfrecord(my_callback, policy=tr.hyperparameters.POLICY)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0a4a1cf",
      "metadata": {
        "id": "b0a4a1cf"
      },
      "source": [
        "## Load the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a51ee383",
      "metadata": {
        "id": "a51ee383"
      },
      "source": [
        "If you did not create a tfrecord and want to load and buffer files from disk directly, set `no_tf_record = True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc2d2068",
      "metadata": {
        "id": "bc2d2068"
      },
      "outputs": [],
      "source": [
        "no_tf_record = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "082c90bf",
      "metadata": {
        "id": "082c90bf"
      },
      "outputs": [],
      "source": [
        "if no_tf_record:\n",
        "    tr.train_data_dir = train_data_dir\n",
        "    tr.test_data_dir = test_data_dir\n",
        "    train.load_data(tr, verbose=0)\n",
        "else:\n",
        "    tr.train_data_dir = os.path.join(dataset_dir, \"tfrecords/train.tfrec\")\n",
        "    tr.test_data_dir = os.path.join(dataset_dir, \"tfrecords/test.tfrec\")\n",
        "    train.load_tfrecord(tr, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edf34f3f",
      "metadata": {
        "id": "edf34f3f"
      },
      "outputs": [],
      "source": [
        "# Select interactive backend to show inline\n",
        "%matplotlib inline\n",
        "utils.show_batch(dataset=tr.train_ds, policy=tr.hyperparameters.POLICY, model=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a5d0f77",
      "metadata": {
        "id": "0a5d0f77"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71034420",
      "metadata": {
        "id": "71034420"
      },
      "source": [
        "The number of epochs is proportional to the training time. One epoch means going through the complete dataset once. Increasing `NUM_EPOCHS` will mean longer training time, but generally leads to better performance. To get familiar with the code it can be set to small values like `5` or `10`. To train a model that performs well, it should be set to values between `50` and `200`. Setting `USE_LAST` to `true` will resume the training from the last checkpoint. The default values are `NUM_EPOCHS = 100` and `USE_LAST = False`. They are set in [Hyperparameters](#hyperparameters)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "894cd54f",
      "metadata": {
        "id": "894cd54f"
      },
      "outputs": [],
      "source": [
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(os.path.join(os.getcwd(), \"models\", tr.model_name), exist_ok=True)\n",
        "\n",
        "# params.NUM_EPOCHS = 200\n",
        "# params.USE_LAST = True\n",
        "train.do_training(tr, my_callback, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cfd4aac",
      "metadata": {
        "id": "0cfd4aac"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f623b65f",
      "metadata": {
        "id": "f623b65f"
      },
      "source": [
        "The loss and mean absolute error should decrease. This indicates that the model is fitting the data well. The custom metrics (direction and angle) should go towards 1. These provide some additional insight to the training progress. The direction metric measures weather or not predictions are in the same direction as the labels. Similarly the angle metric measures if the prediction is within a small angle of the labels. The intuition is that driving in the right direction with the correct steering angle is most critical part for good final performance."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4867aaa7",
      "metadata": {
        "id": "4867aaa7"
      },
      "source": [
        "### Plot metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ca0b291",
      "metadata": {
        "id": "8ca0b291"
      },
      "outputs": [],
      "source": [
        "x = np.arange(tr.INITIAL_EPOCH + 1, tr.history.params[\"epochs\"] + 1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efd65e1a",
      "metadata": {
        "id": "efd65e1a"
      },
      "outputs": [],
      "source": [
        "plt.figure().gca().xaxis.get_major_locator().set_params(integer=True)\n",
        "plt.plot(x, tr.history.history[\"loss\"], label=\"loss\")\n",
        "plt.plot(x, tr.history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.savefig(os.path.join(tr.log_path, \"loss.png\"), bbox_inches=\"tight\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97e98f63",
      "metadata": {
        "id": "97e98f63"
      },
      "outputs": [],
      "source": [
        "plt.figure().gca().xaxis.get_major_locator().set_params(integer=True)\n",
        "plt.plot(x, tr.history.history[\"mean_absolute_error\"], label=\"mean_absolute_error\")\n",
        "plt.plot(\n",
        "    x, tr.history.history[\"val_mean_absolute_error\"], label=\"val_mean_absolute_error\"\n",
        ")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Mean Absolute Error\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.savefig(os.path.join(tr.log_path, \"error.png\"), bbox_inches=\"tight\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa1752d7",
      "metadata": {
        "id": "aa1752d7"
      },
      "outputs": [],
      "source": [
        "plt.figure().gca().xaxis.get_major_locator().set_params(integer=True)\n",
        "plt.plot(x, tr.history.history[\"direction_metric\"], label=\"direction_metric\")\n",
        "plt.plot(x, tr.history.history[\"val_direction_metric\"], label=\"val_direction_metric\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Direction Metric\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig(os.path.join(tr.log_path, \"direction.png\"), bbox_inches=\"tight\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9de04eec",
      "metadata": {
        "id": "9de04eec"
      },
      "outputs": [],
      "source": [
        "plt.figure().gca().xaxis.get_major_locator().set_params(integer=True)\n",
        "plt.plot(x, tr.history.history[\"angle_metric\"], label=\"angle_metric\")\n",
        "plt.plot(x, tr.history.history[\"val_angle_metric\"], label=\"val_angle_metric\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Angle Metric\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig(os.path.join(tr.log_path, \"angle.png\"), bbox_inches=\"tight\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e72c1de3",
      "metadata": {
        "id": "e72c1de3"
      },
      "source": [
        "### Save tf lite models for best train, best val and last checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92a1ef62",
      "metadata": {
        "id": "92a1ef62"
      },
      "outputs": [],
      "source": [
        "best_train_checkpoint = \"cp-best-train.ckpt\"\n",
        "best_train_tflite = utils.generate_tflite(tr.checkpoint_path, best_train_checkpoint)\n",
        "utils.save_tflite(best_train_tflite, tr.checkpoint_path, \"best-train\")\n",
        "best_train_index = np.argmin(np.array(tr.history.history[\"loss\"]))\n",
        "print(\n",
        "    \"Best Train Checkpoint (epoch %s) - angle: %.4f, val_angle: %.4f, direction: %.4f, val_direction: %.4f\"\n",
        "    % (\n",
        "        best_train_index,\n",
        "        tr.history.history[\"angle_metric\"][best_train_index],\n",
        "        tr.history.history[\"val_angle_metric\"][best_train_index],\n",
        "        tr.history.history[\"direction_metric\"][best_train_index],\n",
        "        tr.history.history[\"val_direction_metric\"][best_train_index],\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb605b90",
      "metadata": {
        "id": "bb605b90"
      },
      "outputs": [],
      "source": [
        "best_val_checkpoint = \"cp-best-val.ckpt\"\n",
        "best_val_tflite = utils.generate_tflite(tr.checkpoint_path, best_val_checkpoint)\n",
        "utils.save_tflite(best_val_tflite, tr.checkpoint_path, \"best\")\n",
        "utils.save_tflite(best_val_tflite, tr.checkpoint_path, \"best-val\")\n",
        "best_val_index = np.argmin(np.array(tr.history.history[\"val_loss\"]))\n",
        "print(\n",
        "    \"Best Val Checkpoint (epoch %s) - angle: %.4f, val_angle: %.4f, direction: %.4f, val_direction: %.4f\"\n",
        "    % (\n",
        "        best_val_index,\n",
        "        tr.history.history[\"angle_metric\"][best_val_index],\n",
        "        tr.history.history[\"val_angle_metric\"][best_val_index],\n",
        "        tr.history.history[\"direction_metric\"][best_val_index],\n",
        "        tr.history.history[\"val_direction_metric\"][best_val_index],\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e2b1644",
      "metadata": {
        "id": "0e2b1644"
      },
      "outputs": [],
      "source": [
        "last_checkpoint = \"cp-last.ckpt\"\n",
        "last_tflite = utils.generate_tflite(tr.checkpoint_path, last_checkpoint)\n",
        "utils.save_tflite(last_tflite, tr.checkpoint_path, \"last\")\n",
        "print(\n",
        "    \"Last Checkpoint - angle: %.4f, val_angle: %.4f, direction: %.4f, val_direction: %.4f\"\n",
        "    % (\n",
        "        tr.history.history[\"angle_metric\"][-1],\n",
        "        tr.history.history[\"val_angle_metric\"][-1],\n",
        "        tr.history.history[\"direction_metric\"][-1],\n",
        "        tr.history.history[\"val_direction_metric\"][-1],\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0c57018",
      "metadata": {
        "id": "d0c57018"
      },
      "source": [
        "### Evaluate the best model (train loss) on the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04a03c6d",
      "metadata": {
        "id": "04a03c6d"
      },
      "outputs": [],
      "source": [
        "best_train_model = utils.load_model(\n",
        "    os.path.join(tr.checkpoint_path, best_train_checkpoint),\n",
        "    tr.loss_fn,\n",
        "    tr.metric_list,\n",
        "    tr.custom_objects,\n",
        ")\n",
        "loss, mae, direction, angle = best_train_model.evaluate(\n",
        "    tr.train_ds,\n",
        "    steps=tr.image_count_train / tr.hyperparameters.TRAIN_BATCH_SIZE,\n",
        "    verbose=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92462709",
      "metadata": {
        "id": "92462709"
      },
      "outputs": [],
      "source": [
        "utils.show_batch(\n",
        "    dataset=tr.train_ds, policy=tr.hyperparameters.POLICY, model=best_train_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10a078b1",
      "metadata": {
        "id": "10a078b1"
      },
      "outputs": [],
      "source": [
        "utils.compare_tf_tflite(best_train_model, best_train_tflite)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2ad2605",
      "metadata": {
        "id": "b2ad2605"
      },
      "source": [
        "### Evaluate the best model (val loss) on the validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2ac5b20",
      "metadata": {
        "id": "e2ac5b20"
      },
      "outputs": [],
      "source": [
        "best_val_model = utils.load_model(\n",
        "    os.path.join(tr.checkpoint_path, best_val_checkpoint),\n",
        "    tr.loss_fn,\n",
        "    tr.metric_list,\n",
        "    tr.custom_objects,\n",
        ")\n",
        "loss, mae, direction, angle = best_val_model.evaluate(\n",
        "    tr.test_ds,\n",
        "    steps=tr.image_count_test / tr.hyperparameters.TEST_BATCH_SIZE,\n",
        "    verbose=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8e01e77",
      "metadata": {
        "id": "d8e01e77"
      },
      "outputs": [],
      "source": [
        "utils.show_batch(\n",
        "    dataset=tr.test_ds, policy=tr.hyperparameters.POLICY, model=best_val_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daf9dbac",
      "metadata": {
        "id": "daf9dbac"
      },
      "outputs": [],
      "source": [
        "utils.compare_tf_tflite(best_val_model, best_val_tflite)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29c9d606",
      "metadata": {
        "id": "29c9d606"
      },
      "source": [
        "## Save the notebook as HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c47915f",
      "metadata": {
        "id": "3c47915f"
      },
      "outputs": [],
      "source": [
        "utils.save_notebook()\n",
        "current_file = \"policy_learning.ipynb\"\n",
        "output_file = os.path.join(tr.log_path, \"notebook.html\")\n",
        "utils.output_HTML(current_file, output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa902ebd",
      "metadata": {
        "id": "fa902ebd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}